{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import operator as operator\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "#NOTE: input the training set (and correct outputs) as x and y, when calling NeuralNetwork()\n",
    "#It automatically trains, so you don't need to call the train function\n",
    "\n",
    "#from gradescope_utils.autograder_utils.decorators import weight, visibility\n",
    "#import unittest\n",
    "#from sklearn.model_selection import KFold\n",
    "#import numpy as np\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "#import matplotlib.pyplot as mp\n",
    "\n",
    "\n",
    "def sigmoid(t): #sigmoid function that will be used with the chain rule\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def sigmoid_derivative(p):\n",
    "    return p * (1 - p)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self,x = [[]],y = [],numLayers=2,numNodes=2,eta=5,maxIter=10000):\n",
    "        self.input = np.array(x)\n",
    "        \n",
    "        self.y = []\n",
    "        for i in range(len(y)):\n",
    "            self.y.append( [(y[i])] )\n",
    "        self.y = np.array(self.y)\n",
    "        \n",
    "        self.numLayers = numLayers\n",
    "        self.numNodes = numNodes + 1 #make room for the bias node\n",
    "        self.eta = eta\n",
    "        self.maxIter = maxIter\n",
    "        self.output = []\n",
    "        self.weights = [np.random.uniform(-1,1,(len(x[0]), self.numNodes))] #create the weights from the inputs to the first layer\n",
    "        \n",
    "        for i in range(numLayers-1):\n",
    "            self.weights.append(np.random.uniform(-1,1,(self.numNodes, self.numNodes))) #create the random weights between internal layers\n",
    "        self.weights.append(np.random.uniform(-1,1,(self.numNodes, 1))) #create weights from final layer to output node\n",
    "        self.train(learningRate=eta, maxIterations=maxIter) #immediately start training the NN\n",
    "\n",
    "    def train(self, learningRate, maxIterations):\n",
    "        for i in range(self.maxIter): #no early stopping, the loop always runs maxIter times\n",
    "            self.feedforward()\n",
    "            self.backprop()\n",
    "\n",
    "    def predict(self,x=[]):\n",
    "        self.input = []\n",
    "        self.input.append(np.array(x))\n",
    "        self.feedforward()\n",
    "        print(self.output)\n",
    "        for i in self.output:\n",
    "            if(i[0] < .5):\n",
    "                i[0] = 0 #predict a 1\n",
    "            else:\n",
    "                i[0] = 1 #predict a 5\n",
    "        return self.output\n",
    "\n",
    "    def feedforward(self): #prediction of value given the inputs\n",
    "        self.layerData = [] \n",
    "        oneLayer = np.dot(self.input, self.weights[0]) #2D array\n",
    "        self.layerData.append(sigmoid(oneLayer))\n",
    "        for mat in self.layerData[0]:\n",
    "            mat[self.numNodes-1] = 1.0 #set the bias node: 1\n",
    "            #print(mat)\n",
    "  \n",
    "        #add layers in between input and output\n",
    "        for i in range(1, self.numLayers):\n",
    "            temp = np.dot(self.layerData[i-1], self.weights[i])\n",
    "            self.layerData.append(sigmoid(temp))\n",
    "            for mat in self.layerData[i]:\n",
    "                mat[self.numNodes-1] = 1.0 #set the bias node: 1\n",
    "        #add output layer\n",
    "        temp = []\n",
    "        temp = np.dot(self.layerData[self.numLayers - 1], self.weights[self.numLayers])\n",
    "        self.layerData.append(sigmoid(temp))\n",
    "        self.output = self.layerData[self.numLayers]\n",
    "        \n",
    "        \n",
    "    def backprop(self): #the meat of the program, using gradient descent via the sigmoid function\n",
    "        bpoutput = []  \n",
    "        \n",
    "        delta = (2*(self.y - self.output) * sigmoid_derivative(self.output))\n",
    "        bpoutput.append(np.dot(self.layerData[self.numLayers-1].T, delta))\n",
    "        dotWithCurrentLayer = []\n",
    "        \n",
    "        for i in range(self.numLayers-1, 0, -1):\n",
    "            dotBPAndWeights = np.dot(delta, self.weights[i+1].T) #delta is the delta of the node 1 index higher\n",
    "            delta = dotBPAndWeights * sigmoid_derivative(self.layerData[i])\n",
    "            bpoutput.append(np.dot(self.layerData[i].T, delta))\n",
    "        \n",
    "        dotFirst = np.dot(delta, self.weights[1].T)\n",
    "        delta = dotFirst * sigmoid_derivative(self.layerData[0])\n",
    "        bpoutput.append(np.dot(self.input.T, delta))\n",
    "                \n",
    "        x = self.numLayers\n",
    "        for mat in self.weights:\n",
    "            mat += self.eta*bpoutput[x]\n",
    "            x = x - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
